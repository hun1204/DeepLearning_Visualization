{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF 2.x cifar_10_residual_block.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNw0D233vtf8"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
        "\n",
        "import os\n",
        "import tensorflow"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnmfOuF4z9qY"
      },
      "source": [
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 50"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6Xtvi_t0GDf",
        "outputId": "bc616c5b-2eb4-4fb5-d6d5-269851a914f4"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train.shape : ', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "x_train.shape :  (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uT5kxw8Q0bUo",
        "outputId": "bb35d182-5faa-45c7-9be0-54b993f267f0"
      },
      "source": [
        "y_train[1]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9vJ9Cmj6Imf"
      },
      "source": [
        "y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbR08KTH0dcW"
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDh2chra3rNH"
      },
      "source": [
        "def residual_block(x, nkernels = 8):\n",
        "  identity = x\n",
        "\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = Conv2D(nkernels, 3, activation=None, kernel_initializer='he_normal', padding='same')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = Conv2D(nkernels, 3, activation=None, kernel_initializer='he_normal', padding='same')(x)\n",
        "\n",
        "  return Activation('relu')(x + identity)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1aIOwZp40Zl"
      },
      "source": [
        "def model(sz=(32,32,3)):\n",
        "  inputs = Input(sz)\n",
        "  \n",
        "  x = Conv2D(8,3, activation=None, kernel_initializer='he_normal', padding='same')(inputs)\n",
        "  \n",
        "  x = residual_block(x)\n",
        "  x = MaxPooling2D()(x)\n",
        "  x = residual_block(x)\n",
        "  x = MaxPooling2D()(x)\n",
        "  x = residual_block(x)\n",
        "  x = MaxPooling2D()(x)\n",
        "  x = Flatten()(x)\n",
        "  last = Dense(10,activation='softmax')(x)\n",
        "  \n",
        "  model = Model(inputs=inputs, outputs=last)\n",
        "  model.compile(optimizer = 'rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qSDnNfS7FSt"
      },
      "source": [
        "residual_model = model()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzVMRCxw71vW",
        "outputId": "f5aad95d-296c-4034-eebc-1dab181330f2"
      },
      "source": [
        "residual_model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 8)    224         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 8)    32          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 8)    0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 8)    584         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 8)    32          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 8)    0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 8)    584         activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add (TFOpLambd (None, 32, 32, 8)    0           conv2d_2[0][0]                   \n",
            "                                                                 conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 8)    0           tf.__operators__.add[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 16, 16, 8)    0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 16, 16, 8)    32          max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 16, 16, 8)    0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 16, 16, 8)    584         activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 16, 16, 8)    32          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 16, 16, 8)    0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 16, 16, 8)    584         activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_1 (TFOpLam (None, 16, 16, 8)    0           conv2d_4[0][0]                   \n",
            "                                                                 max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 8)    0           tf.__operators__.add_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 8)      0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 8, 8, 8)      32          max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 8, 8, 8)      0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 8, 8, 8)      584         activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 8, 8, 8)      32          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 8, 8, 8)      0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 8, 8, 8)      584         activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_2 (TFOpLam (None, 8, 8, 8)      0           conv2d_6[0][0]                   \n",
            "                                                                 max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 8, 8, 8)      0           tf.__operators__.add_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 8)      0           activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 128)          0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           1290        flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 5,210\n",
            "Trainable params: 5,114\n",
            "Non-trainable params: 96\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4CbTmFU76pe",
        "outputId": "3f9adfa4-db25-47d2-8fd2-5ee05c628ad7"
      },
      "source": [
        "trained_model = residual_model.fit(x_train,y_train, batch_size=batch_size,\n",
        "                                   epochs=epochs\n",
        "                                   ,validation_data=(x_test,y_test),\n",
        "                                   shuffle=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "782/782 [==============================] - 39s 8ms/step - loss: 1.8335 - accuracy: 0.3370 - val_loss: 1.8372 - val_accuracy: 0.3392\n",
            "Epoch 2/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.4831 - accuracy: 0.4606 - val_loss: 1.5147 - val_accuracy: 0.4531\n",
            "Epoch 3/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.3755 - accuracy: 0.5000 - val_loss: 1.3611 - val_accuracy: 0.5030\n",
            "Epoch 4/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2993 - accuracy: 0.5313 - val_loss: 1.3279 - val_accuracy: 0.5242\n",
            "Epoch 5/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2359 - accuracy: 0.5559 - val_loss: 1.2522 - val_accuracy: 0.5463\n",
            "Epoch 6/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1760 - accuracy: 0.5780 - val_loss: 1.1849 - val_accuracy: 0.5745\n",
            "Epoch 7/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1275 - accuracy: 0.5984 - val_loss: 1.4576 - val_accuracy: 0.5070\n",
            "Epoch 8/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0962 - accuracy: 0.6100 - val_loss: 1.2438 - val_accuracy: 0.5573\n",
            "Epoch 9/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0688 - accuracy: 0.6199 - val_loss: 1.1911 - val_accuracy: 0.5745\n",
            "Epoch 10/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0447 - accuracy: 0.6271 - val_loss: 1.1963 - val_accuracy: 0.5788\n",
            "Epoch 11/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.0261 - accuracy: 0.6360 - val_loss: 1.0786 - val_accuracy: 0.6187\n",
            "Epoch 12/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.0106 - accuracy: 0.6412 - val_loss: 1.2609 - val_accuracy: 0.5620\n",
            "Epoch 13/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.9946 - accuracy: 0.6466 - val_loss: 1.1177 - val_accuracy: 0.6030\n",
            "Epoch 14/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9793 - accuracy: 0.6524 - val_loss: 1.0685 - val_accuracy: 0.6236\n",
            "Epoch 15/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9672 - accuracy: 0.6565 - val_loss: 1.1573 - val_accuracy: 0.6006\n",
            "Epoch 16/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9580 - accuracy: 0.6601 - val_loss: 1.4052 - val_accuracy: 0.5396\n",
            "Epoch 17/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9486 - accuracy: 0.6650 - val_loss: 1.2633 - val_accuracy: 0.5671\n",
            "Epoch 18/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9378 - accuracy: 0.6686 - val_loss: 1.1992 - val_accuracy: 0.5846\n",
            "Epoch 19/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9280 - accuracy: 0.6711 - val_loss: 1.1605 - val_accuracy: 0.5918\n",
            "Epoch 20/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9216 - accuracy: 0.6747 - val_loss: 0.9883 - val_accuracy: 0.6559\n",
            "Epoch 21/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.9125 - accuracy: 0.6763 - val_loss: 1.0197 - val_accuracy: 0.6474\n",
            "Epoch 22/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9068 - accuracy: 0.6785 - val_loss: 1.0541 - val_accuracy: 0.6290\n",
            "Epoch 23/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9043 - accuracy: 0.6804 - val_loss: 1.1372 - val_accuracy: 0.6126\n",
            "Epoch 24/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8958 - accuracy: 0.6824 - val_loss: 1.1185 - val_accuracy: 0.6131\n",
            "Epoch 25/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8904 - accuracy: 0.6853 - val_loss: 1.1159 - val_accuracy: 0.6131\n",
            "Epoch 26/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8853 - accuracy: 0.6874 - val_loss: 1.3463 - val_accuracy: 0.5640\n",
            "Epoch 27/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8806 - accuracy: 0.6898 - val_loss: 1.0476 - val_accuracy: 0.6407\n",
            "Epoch 28/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8779 - accuracy: 0.6901 - val_loss: 0.9915 - val_accuracy: 0.6556\n",
            "Epoch 29/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8731 - accuracy: 0.6939 - val_loss: 1.0321 - val_accuracy: 0.6418\n",
            "Epoch 30/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8670 - accuracy: 0.6934 - val_loss: 1.2683 - val_accuracy: 0.5815\n",
            "Epoch 31/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8619 - accuracy: 0.6950 - val_loss: 1.0085 - val_accuracy: 0.6521\n",
            "Epoch 32/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8599 - accuracy: 0.6964 - val_loss: 1.0134 - val_accuracy: 0.6500\n",
            "Epoch 33/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8549 - accuracy: 0.6975 - val_loss: 1.0531 - val_accuracy: 0.6411\n",
            "Epoch 34/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8522 - accuracy: 0.6983 - val_loss: 1.0231 - val_accuracy: 0.6455\n",
            "Epoch 35/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8490 - accuracy: 0.7003 - val_loss: 1.0734 - val_accuracy: 0.6317\n",
            "Epoch 36/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8479 - accuracy: 0.6992 - val_loss: 1.0255 - val_accuracy: 0.6460\n",
            "Epoch 37/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8420 - accuracy: 0.7025 - val_loss: 1.0205 - val_accuracy: 0.6468\n",
            "Epoch 38/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.8409 - accuracy: 0.7007 - val_loss: 1.0528 - val_accuracy: 0.6493\n",
            "Epoch 39/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8369 - accuracy: 0.7041 - val_loss: 1.0029 - val_accuracy: 0.6516\n",
            "Epoch 40/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8358 - accuracy: 0.7048 - val_loss: 1.0272 - val_accuracy: 0.6519\n",
            "Epoch 41/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8342 - accuracy: 0.7043 - val_loss: 0.9786 - val_accuracy: 0.6631\n",
            "Epoch 42/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8314 - accuracy: 0.7049 - val_loss: 0.9761 - val_accuracy: 0.6616\n",
            "Epoch 43/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8284 - accuracy: 0.7083 - val_loss: 1.0555 - val_accuracy: 0.6473\n",
            "Epoch 44/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8267 - accuracy: 0.7072 - val_loss: 1.0615 - val_accuracy: 0.6476\n",
            "Epoch 45/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8229 - accuracy: 0.7105 - val_loss: 1.1105 - val_accuracy: 0.6237\n",
            "Epoch 46/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8203 - accuracy: 0.7103 - val_loss: 1.0092 - val_accuracy: 0.6539\n",
            "Epoch 47/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8201 - accuracy: 0.7078 - val_loss: 1.0389 - val_accuracy: 0.6487\n",
            "Epoch 48/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8175 - accuracy: 0.7100 - val_loss: 0.9920 - val_accuracy: 0.6563\n",
            "Epoch 49/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8153 - accuracy: 0.7113 - val_loss: 1.0672 - val_accuracy: 0.6357\n",
            "Epoch 50/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8135 - accuracy: 0.7124 - val_loss: 1.0259 - val_accuracy: 0.6539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_55GrBO80zG",
        "outputId": "ecc4a949-ed7f-4cde-cd11-9fd2e488764a"
      },
      "source": [
        "epochs_range = range(50)\n",
        "print(trained_model.history)\n",
        "print(trained_model.history.keys())\n",
        "validation_accuracy = trained_model.history['val_accuracy']\n",
        "training_accuracy = trained_model.history['accuracy']"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'loss': [1.8334769010543823, 1.4830681085586548, 1.37545907497406, 1.2993040084838867, 1.235893964767456, 1.1759663820266724, 1.1275464296340942, 1.0962040424346924, 1.06881844997406, 1.0447485446929932, 1.026107668876648, 1.010591745376587, 0.9946355223655701, 0.9792935252189636, 0.9671753644943237, 0.9580295085906982, 0.9486027956008911, 0.9378054738044739, 0.9280350804328918, 0.9216258525848389, 0.9124934077262878, 0.906765341758728, 0.9042941927909851, 0.8957657217979431, 0.8903532028198242, 0.8852856755256653, 0.8806427121162415, 0.8778669238090515, 0.8730667233467102, 0.8669783473014832, 0.8619470596313477, 0.8599385023117065, 0.8549243211746216, 0.8521654009819031, 0.8489768505096436, 0.8478867411613464, 0.8419650793075562, 0.8409141898155212, 0.8369027972221375, 0.835769534111023, 0.8342205286026001, 0.8313754200935364, 0.8284389972686768, 0.8267154097557068, 0.8229255676269531, 0.8202793002128601, 0.8200817108154297, 0.8175103068351746, 0.8152833580970764, 0.8135371208190918], 'accuracy': [0.3370400071144104, 0.4605799913406372, 0.5000399947166443, 0.531279981136322, 0.5558800101280212, 0.5780199766159058, 0.5983800292015076, 0.6100000143051147, 0.6199399828910828, 0.6270599961280823, 0.6359599828720093, 0.641219973564148, 0.6466400027275085, 0.6523600220680237, 0.6564599871635437, 0.6601399779319763, 0.6649600267410278, 0.6686400175094604, 0.6711199879646301, 0.6746799945831299, 0.6763200163841248, 0.6785399913787842, 0.680400013923645, 0.6823800206184387, 0.685259997844696, 0.6873999834060669, 0.6898199915885925, 0.690060019493103, 0.6939200162887573, 0.6933799982070923, 0.6949599981307983, 0.6963800191879272, 0.6974599957466125, 0.6983199715614319, 0.7002800107002258, 0.6992400288581848, 0.702459990978241, 0.7007200121879578, 0.7041000127792358, 0.704800009727478, 0.7043200135231018, 0.7049000263214111, 0.7082599997520447, 0.7071800231933594, 0.7105000019073486, 0.710319995880127, 0.7077599763870239, 0.7099800109863281, 0.7112799882888794, 0.7123799920082092], 'val_loss': [1.837181806564331, 1.514687180519104, 1.3610769510269165, 1.3279489278793335, 1.2522103786468506, 1.1848552227020264, 1.4575538635253906, 1.2438099384307861, 1.191071629524231, 1.1963297128677368, 1.0785638093948364, 1.2608741521835327, 1.1177244186401367, 1.068505048751831, 1.157310128211975, 1.4052308797836304, 1.2633496522903442, 1.1991702318191528, 1.160502314567566, 0.9882645606994629, 1.0197417736053467, 1.0541069507598877, 1.13724946975708, 1.118453025817871, 1.1159298419952393, 1.3463047742843628, 1.0475964546203613, 0.9914677739143372, 1.03206205368042, 1.2683205604553223, 1.008545160293579, 1.0134485960006714, 1.0530952215194702, 1.0231115818023682, 1.0733717679977417, 1.025549292564392, 1.020490288734436, 1.0528271198272705, 1.0029486417770386, 1.0271974802017212, 0.9786349534988403, 0.9760720729827881, 1.0555126667022705, 1.0615408420562744, 1.1104966402053833, 1.009203314781189, 1.0389366149902344, 0.9920471906661987, 1.0671956539154053, 1.0258840322494507], 'val_accuracy': [0.3391999900341034, 0.4530999958515167, 0.503000020980835, 0.5242000222206116, 0.5462999939918518, 0.5745000243186951, 0.5070000290870667, 0.5572999715805054, 0.5745000243186951, 0.5788000226020813, 0.6187000274658203, 0.5619999766349792, 0.6029999852180481, 0.6236000061035156, 0.600600004196167, 0.5396000146865845, 0.5670999884605408, 0.5845999717712402, 0.5917999744415283, 0.6559000015258789, 0.6474000215530396, 0.6290000081062317, 0.6126000285148621, 0.613099992275238, 0.613099992275238, 0.5640000104904175, 0.6406999826431274, 0.6556000113487244, 0.6417999863624573, 0.5814999938011169, 0.6521000266075134, 0.6499999761581421, 0.6410999894142151, 0.6455000042915344, 0.6316999793052673, 0.6460000276565552, 0.6467999815940857, 0.6492999792098999, 0.6516000032424927, 0.6518999934196472, 0.663100004196167, 0.6615999937057495, 0.6473000049591064, 0.647599995136261, 0.6237000226974487, 0.6539000272750854, 0.6486999988555908, 0.6563000082969666, 0.635699987411499, 0.6539000272750854]}\n",
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "TBzK276v98Se",
        "outputId": "5b2e1883-e800-4e1b-93f9-93e8293573a6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(epochs_range, training_accuracy, 'b+', label='training accuracy')\n",
        "plt.plot(epochs_range, validation_accuracy, 'bo', label='validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGtFc8jO-plg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ca582e4-c604-4252-8162-959a182b5c2e"
      },
      "source": [
        "scores = residual_model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 1.0259 - accuracy: 0.6539\n",
            "Test loss: 1.0258840322494507\n",
            "Test accuracy: 0.6539000272750854\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}